from typing import Any, Optional, Union, List, Tuple, overload, TypeVar, Iterator
from torch import device, dtype

class Tensor:
    shape: Tuple[int, ...]
    dtype: dtype
    device: device
    requires_grad: bool
    grad: Optional['Tensor']
    
    @overload
    def __init__(self) -> None: ...
    @overload 
    def __init__(self, data: Any, dtype: Optional[dtype] = None, device: Optional[device] = None, requires_grad: bool = False) -> None: ...
    
    def to(self, device: Union[device, str], dtype: Optional[dtype] = None, non_blocking: bool = False) -> 'Tensor': ...
    def cuda(self, device: Optional[Union[device, int]] = None, non_blocking: bool = False) -> 'Tensor': ...
    def cpu(self) -> 'Tensor': ...
    
    def backward(self, gradient: Optional['Tensor'] = None, retain_graph: bool = False, create_graph: bool = False) -> None: ...
    def detach(self) -> 'Tensor': ...
    def numpy(self) -> Any: ...  # numpy.ndarray
    
    # Math operations
    def add(self, other: Union['Tensor', float], *, alpha: float = 1) -> 'Tensor': ...
    def sub(self, other: Union['Tensor', float], *, alpha: float = 1) -> 'Tensor': ...
    def mul(self, other: Union['Tensor', float]) -> 'Tensor': ...
    def div(self, other: Union['Tensor', float]) -> 'Tensor': ...
    def matmul(self, other: 'Tensor') -> 'Tensor': ...
    
    # Shape operations
    def view(self, *shape: int) -> 'Tensor': ...
    def reshape(self, *shape: int) -> 'Tensor': ...
    def permute(self, *dims: int) -> 'Tensor': ...
    def transpose(self, dim0: int, dim1: int) -> 'Tensor': ...
    def squeeze(self, dim: Optional[int] = None) -> 'Tensor': ...
    def unsqueeze(self, dim: int) -> 'Tensor': ...
    
    # Reduction operations
    def sum(self, dim: Optional[Union[int, Tuple[int, ...]]] = None, keepdim: bool = False) -> 'Tensor': ...
    def mean(self, dim: Optional[Union[int, Tuple[int, ...]]] = None, keepdim: bool = False) -> 'Tensor': ...
    def max(self, dim: Optional[int] = None, keepdim: bool = False) -> Union['Tensor', Tuple['Tensor', 'Tensor']]: ...
    def min(self, dim: Optional[int] = None, keepdim: bool = False) -> Union['Tensor', Tuple['Tensor', 'Tensor']]: ...
    
    # Comparison operations
    def eq(self, other: Union['Tensor', float]) -> 'Tensor': ...
    def ne(self, other: Union['Tensor', float]) -> 'Tensor': ...
    def lt(self, other: Union['Tensor', float]) -> 'Tensor': ...
    def le(self, other: Union['Tensor', float]) -> 'Tensor': ...
    def gt(self, other: Union['Tensor', float]) -> 'Tensor': ...
    def ge(self, other: Union['Tensor', float]) -> 'Tensor': ...
    
    # Activation functions
    def relu(self) -> 'Tensor': ...
    def sigmoid(self) -> 'Tensor': ...
    def tanh(self) -> 'Tensor': ...
    def softmax(self, dim: int) -> 'Tensor': ...
    
    # Other operations
    def clone(self) -> 'Tensor': ...
    def contiguous(self) -> 'Tensor': ...
    def zero_(self) -> 'Tensor': ...
    def fill_(self, value: float) -> 'Tensor': ...
    def normal_(self, mean: float = 0, std: float = 1) -> 'Tensor': ...
    
    def __len__(self) -> int: ...
    def __iter__(self) -> Iterator['Tensor']: ...
    def __getitem__(self, idx: Any) -> 'Tensor': ...
    def __setitem__(self, idx: Any, val: Any) -> None: ... 