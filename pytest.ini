[pytest]
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Test categories
markers =
    # Core test types
    unit: Unit tests
    integration: Integration tests
    e2e: mark a test as end-to-end test
    benchmark: mark a test as a performance benchmark
    
    # Performance categories
    slow: Tests that take longer to run
    very_slow: mark a test as very slow running (>5s)
    performance_critical: mark performance-critical components
    memory_intensive: mark tests that require significant memory
    
    # Infrastructure requirements
    monitoring: mark a test as monitoring-related
    visualization: mark a test as visualization-related
    network: Tests that require network connectivity
    redis: mark a test as requiring Redis
    prometheus: mark a test as requiring Prometheus
    jaeger: mark a test as requiring Jaeger
    
    # Security and reliability
    security: mark a test as security-related
    security_critical: mark tests of security-critical components
    penetration: mark penetration testing scenarios
    fuzzing: mark fuzzing test cases
    chaos: mark a test as chaos testing
    reliability: mark reliability test scenarios
    recovery: mark disaster recovery test scenarios
    
    # Smart contract testing
    contract: mark a test as smart contract testing
    contract_unit: mark contract unit tests
    contract_integration: mark contract integration tests
    contract_upgrade: mark contract upgrade tests
    contract_security: mark contract security tests
    contract_gas: mark gas optimization tests
    
    # Data and state
    stateful: mark stateful tests
    stateless: mark stateless tests
    database: mark database-dependent tests
    cache: mark cache-dependent tests
    
    # API and Protocol
    api: mark API tests
    rest: mark REST API tests
    websocket: mark WebSocket tests
    grpc: mark gRPC tests
    blockchain_rpc: mark blockchain RPC tests
    
    # Market and Trading
    market: mark market-related tests
    trading: mark trading-related tests
    arbitrage: mark arbitrage-specific tests
    dex: mark DEX-specific tests
    amm: mark AMM-specific tests
    
    # Environment and configuration
    dev: mark development environment tests
    staging: mark staging environment tests
    prod: mark production environment tests
    config: mark configuration tests
    
    # Compliance and validation
    compliance: mark regulatory compliance tests
    audit: mark audit-related tests
    validation: mark input validation tests
    sanitization: mark data sanitization tests

# Test discovery
testpaths =
    tests/core
    tests/integration
    tests/execution
    tests/performance
    tests/security
    tests/chaos
    tests/contracts
    tests/e2e
    tests/compliance
    tests/reliability

python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test execution
addopts =
    --strict-markers
    --tb=short
    -v
    --durations=10
    --maxfail=1
    --disable-warnings
    -n auto
    --dist loadfile
    --cov=src
    --cov-report=term-missing
    --cov-report=xml
    --cov-report=html
    --cov-branch
    --benchmark-only
    --benchmark-autosave
    --benchmark-compare
    --benchmark-compare-fail=min:5%
    --benchmark-columns=min,max,mean,stddev,median,iqr
    --hypothesis-show-statistics
    --html=test-report.html
    --self-contained-html
    --json-report
    --json-report-file=test-results.json

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Filter warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::UserWarning
    ignore::RuntimeWarning
    ignore::pytest.PytestUnknownMarkWarning

# Coverage settings
[coverage:run]
branch = True
source = src
omit =
    src/migrations/*
    src/tests/*
    src/*/__init__.py
    src/scripts/*
    src/tools/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise NotImplementedError
    if __name__ == .__main__.:
    pass
    raise ImportError
    except ImportError:
    if TYPE_CHECKING:
    @abstractmethod
    @abc.abstractmethod
    class .*\bProtocol\):
    class .*\bInterface\):

# Performance testing settings
[benchmark]
min_rounds = 100
max_time = 2.0
warmup = true
calibration_precision = 1%
disable_gc = true
timer = time.perf_counter
compare = 
    min:5%
    max:10%
group_by = name
columns = min,max,mean,stddev,median,iqr

# Hypothesis settings
[hypothesis]
deadline = 500
max_examples = 1000
derandomize = true
print_blob = true
stateful_step_count = 50
suppress_health_check = 
    too_slow
    data_too_large
    filter_too_much
    function_scoped_fixture

# Environment variables for tests
env =
    PYTHONPATH=src
    TEST_ENV=test
    TEST_ETHEREUM_RPC=http://localhost:8545
    TEST_BASE_RPC=http://localhost:8546
    TEST_POLYGON_RPC=http://localhost:8547 